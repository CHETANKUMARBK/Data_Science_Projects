{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest regressor, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "url = \"http://www.indeed.com/jobs?q=data+scientist&l=New+York%2C+NY&start=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "# try out scraping function on a single page to see if it scrapes the right contents successfully\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "jobs=[]\n",
    "for post in soup.find_all('div', {'class':' row result'}):\n",
    "    job={}\n",
    "    job['title'] = post.find('a').get('title')\n",
    "    try:\n",
    "        job['company'] = post.find('span', {'itemprop':'name'}).getText()\n",
    "    except:\n",
    "        job['company'] = None\n",
    "    job['location'] = post.find('span', {'class':'location'}).getText()\n",
    "    job['summary'] = post.find('span', {'class':'summary'}).getText()\n",
    "    try:\n",
    "        job['salary'] = post.find('td', {'class':'snip'}).find('nobr').renderContents()\n",
    "    except:\n",
    "        job['salary'] = None\n",
    "    jobs.append(job)\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "# try to convert contents into dataframe to take a look\n",
    "import pandas as pd\n",
    "test = pd.DataFrame(jobs)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "# create a function to automatically go through pages and scrape results for more cities\n",
    "\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 5000 # Set this to a high-value (5000) to generate more results. \n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'Virginia']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        for post in soup.find_all('div', {'class':' row result'}):\n",
    "            result={}\n",
    "            try:\n",
    "                result['company'] = post.find('span', {'itemprop':'name'}).getText()\n",
    "            except:\n",
    "                result['company'] = None\n",
    "            result['title'] = post.find('a').get('title')\n",
    "            result['location'] = post.find('span', {'class':'location'}).getText()\n",
    "            result['summary'] = post.find('span', {'class':'summary'}).getText()\n",
    "            try:\n",
    "                result['salary'] = post.find('td', {'class':'snip'}).find('nobr').renderContents()\n",
    "            except:\n",
    "                result['salary'] = None\n",
    "            results.append(result)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "# convert results to dataframe\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save raw data to a file\n",
    "\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "df.to_csv('~/desktop/dsjobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "# Find the entries with annual salary entries, \n",
    "# by filtering the entries without salaries or salaries that are not yearly \n",
    "#(filter those that refer to hour or week). Also, remove duplicate entries\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df.salary.str.contains('hour')==False]\n",
    "df = df[df.salary.str.contains('week')==False]\n",
    "df = df[df.salary.str.contains('month')==False]\n",
    "df = df[df.salary.str.contains('day')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean strings\n",
    "df.summary = df.summary.apply(lambda x: x.strip())\n",
    "df.company = df.company.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert salary string to number, and average a salary range\n",
    "\n",
    "df.salary = df.salary.apply(lambda x: x.replace(' a year', ''))\n",
    "df.salary = df.salary.apply(lambda x: x.replace('$', ''))\n",
    "df.salary = df.salary.apply(lambda x: x.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def number(x):\n",
    "    if '-' in x:\n",
    "        return (int(x.split('-')[0])+int(x.split('-')[1]))/2\n",
    "    else:\n",
    "        return int(x)\n",
    "df.salary = df.salary.apply(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "df.to_csv('~/desktop/cleandata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/desktop/cleandata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "# create binary dependent variable\n",
    "\n",
    "import numpy as np\n",
    "data['high_salary'] = data.salary.apply(lambda x: 0 if x<np.median(data.salary) else 1)\n",
    "data.rename(columns={'company': 'employer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "# check the benchmark\n",
    "\n",
    "float(data.high_salary.sum())/len(data.high_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uniform location to city level\n",
    "\n",
    "def place(x):\n",
    "    return x.split(',')[0] + ', ' + x.split(',')[1][0:3]\n",
    "data.location = data.location.apply(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "# label categorical feature\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "rf = RandomForestClassifier()\n",
    "le = LabelEncoder()\n",
    "data['location_num'] = le.fit_transform(data.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.location_num.reshape(-1, 1)\n",
    "y = data.high_salary\n",
    "rf.fit(X, y)\n",
    "print rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "# create a categorical feature from 'title'\n",
    "\n",
    "def position(x):\n",
    "    if 'Manager' in x:\n",
    "        return 3\n",
    "    elif 'Principal' in x:\n",
    "        return 2\n",
    "    elif 'Senior' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['high_position'] = data.title.apply(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.high_position.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[['location_num', 'high_position']]\n",
    "rf.fit(X, y)\n",
    "print rf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try NLP on summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "# create text matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit(data.summary)\n",
    "words = pd.DataFrame(tvec.transform(data.summary).todense(), columns = tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge text matrix back to main dataframe\n",
    "\n",
    "df = pd.concat([data, words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "# utilize random forest to select features\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "X = df.iloc[:,6:]\n",
    "y = df.high_salary\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[['location_num', 'high_position', 'scientists', 'data', 'big', 'scientist', 'team', 'analysis', 'analytics', \n",
    "       'large', 'looking', 'responsible', 'company', 'python', 'experience']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utilize grid search to optimize parameters\n",
    "\n",
    "cv = KFold(len(y), n_folds=5, shuffle=True)\n",
    "rf_params = {'n_estimators': [5,10,15,20], 'criterion': ['gini', 'entropy'], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "rfgs = GridSearchCV(rf, rf_params)\n",
    "rfgs.fit(X, y)\n",
    "print rfgs.best_params_\n",
    "print rfgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the best model from grid search to check the cross validation score\n",
    "\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "rf = RandomForestClassifier(max_features='auto', n_estimators=10, criterion='entropy')\n",
    "rfscore = cross_val_score(rf, X, y, cv=cv, n_jobs=-1).mean()\n",
    "rf_pred = cross_val_predict(rf, X, y, cv=cv, n_jobs=-1)\n",
    "print rfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "conmat = np.array(confusion_matrix(y, rf_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['high', 'low'], columns=['pred high', 'pred low'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the roc curve and calculate auc\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)\n",
    "rf.fit(X_train, y_train)\n",
    "y_prob = rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc=dict()\n",
    "fpr[1], tpr[1], _ = roc_curve(y_test, y_prob)\n",
    "roc_auc[1] = auc(fpr[1], tpr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(fpr[1], tpr[1], label='ROC curve (area = %0.2f)' % roc_auc[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic for high salary', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to use boosting to see if the accuracy score improve\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_params = {'n_estimators': [100, 200, 250, 300], 'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "gbcgs = GridSearchCV(gbc, gbc_params)\n",
    "gbcgs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gbcgs.best_params_\n",
    "print gbcgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict, KFold\n",
    "cv = KFold(len(y), n_folds=5, shuffle=True)\n",
    "gbc = GradientBoostingClassifier(max_features='sqrt', n_estimators=100)\n",
    "gbcscore = cross_val_score(gbc, X, y, cv=cv, n_jobs=1).mean()\n",
    "gbc_pred = cross_val_predict(gbc, X, y, cv=cv, n_jobs=1)\n",
    "print gbcscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "# create dummies for categorical features\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categorical_features=[0,1])\n",
    "X = enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid search\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf_params = {'kernel': ['rbf', 'sigmoid', 'linear', 'poly'], 'C': 10.**np.arange(-2,3), \n",
    "              'gamma': 10.**np.arange(-5,2), 'degree': [2,3,4]}\n",
    "clfgs = GridSearchCV(clf, clf_params)\n",
    "clfgs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clfgs.best_params_\n",
    "print clfgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=100.0, probability=True)\n",
    "clfscore = cross_val_score(clf, X, y, cv=cv, n_jobs=-1).mean()\n",
    "clf_pred = cross_val_predict(clf, X, y, cv=cv, n_jobs=-1)\n",
    "print clfscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print evaluation matrices\n",
    "\n",
    "clfcm = np.array(confusion_matrix(y, clf_pred, labels=[1,0]))\n",
    "clf_confusion = pd.DataFrame(clfcm, index=['high', 'low'], columns=['pred high', 'pred low'])\n",
    "clf_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(y, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "clf_prob = clf.predict_proba(X_test)[:,1]\n",
    "clffpr = dict()\n",
    "clftpr = dict()\n",
    "clfroc_auc=dict()\n",
    "clffpr[1], clftpr[1], _ = roc_curve(y_test, clf_prob)\n",
    "clfroc_auc[1] = auc(clffpr[1], clftpr[1])\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(clffpr[1], clftpr[1], label='ROC curve (area = %0.2f)' % clfroc_auc[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic for high salary (SVM)', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
